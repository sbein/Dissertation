\chapter{The Viability of SUSY: The pMSSM Interpretation}
\label{chap:run1pmssm}
CMS has performed many searches for evidence of SUSY at the LHC. To assess the impact of a representative set of these searches on the MSSM, an interpretation has been performed in the framework of the phenomenological MSSM (pMSSM), taken as a proxy for the MSSM (see Section~\ref{sec:pmssm} for an introduction to the pMSSM).  A global Bayesian analysis is performed, incorporating results from a broad range of CMS searches, as well as constraints from other experiments. Because the pMSSM incorporates several well-motivated assumptions that reduce the 120 parameters of the MSSM to just 19 parameters defined at the electroweak scale, it is possible to assess the how the MSSM is constrained in a relatively straightforward way. 

This chapter begins with a brief introduction to Bayes' theorem, and follows with excerpts from the paper \cite{bib:pMSSM}. These sections are augmented by additional key details not discussed in the paper, including a discussion of the robustness of the results with respect to the choice of prior (prior is defined in the next section), and an expanded discussion of the non-excluded regions. But first, a short introduction to Bayes' theorem.

\section{Bayes' theorem}
Bayes' theorem, or ``the Pythagorean theorem [of] geometry,'' according to eminent statistician Harold Jeffreys~\cite{Jeffreys:Inference}, is a fundamental statement in probability theory relating conditional and absolute probabilities. If A and B represent two potentially true statements, 
\begin{itemize}
\item P(A) and P(B) are the absolute probabilities of A and B being true, respectively, and
\item P(A|B) is the conditional probability of A being true given that B is true,
\end{itemize}
then Bayes' theorem is
\begin{equation}
\text{P(A|B)}=\frac{\text{P(B|A)P(A)}}{\text{P(B)}}.
\end{equation}
Bayes' theorem is applicable in many physics problems as a means of inference, namely, as a way of inferring knowledge about a theory given data:
\begin{equation}
\text{P(theory|data)}=\frac{\text{P(data|theory)P(theory)}}{\text{P(data)}}=\text{P(data|theory)P(theory)},
\end{equation}
where P(data) has been set to 1. In this expression, the factor P(theory) is called the prior probability density, and it incorporates knowledge about a given theory prior to the consideration of the data at hand;  \text{P(data|theory)} is referred to as the likelihood, and incorporates the data into our knowledge about the theory; P(theory|data) is the so-called posterior probability density, and represents our state of knowledge about the theory given all information available. Bayesian inference is used in the following sections, as well as in the Chapter \ref{chap:susysearches} in the context of QCD background estimation.

\section{Methods for the combination CMS analyses}
\label{sec:anl}
The purpose of this work is to assess how the current data constrain the MSSM using the more tractable pMSSM as a proxy.  We use the results from several CMS analyses, which cover a
variety of final states, to construct posterior densities of model
parameters, masses, and observables. The posterior density of the
model parameters, which are denoted by $\theta$, is given by 
\begin{equation}
	p(\theta|D^\textrm{CMS}) \propto L(D^\textrm{CMS} | \theta\, ) \, p^\textrm{non-DCS}(\theta),
	\label{eq:posterior}
\end{equation}
where $D^\textrm{CMS}$ denotes the data analyzed by the direct CMS
SUSY searches, $L(D^\textrm{CMS} | \theta\, )$ is the associated CMS
likelihood that
incorporates the impact of these direct CMS searches, and
$p^\textrm{non-DCS}(\theta)$ is the prior density constructed from
results not based on direct CMS SUSY searches (non-DCS results).
%where $D^\textrm{CMS}$ denotes the CMS data, $L(D^\textrm{CMS} | \theta )$ the associated CMS likelihood, and $p^\textrm{non-DCS}(\theta)$ the prior density constructed from results other than those from direct CMS searches (DCS). 
The posterior density for an observable $\lambda$ is obtained as follows,
\begin{equation}
	p(\lambda|D^\textrm{CMS}) = \int \delta[\lambda- \lambda^\prime(\theta)] \, p(\theta| D^\textrm{CMS}) \, d\theta,
	\label{eq:lambda}
\end{equation}
where $\lambda^\prime(\theta)$ is the value of the observable as
predicted by model point $\theta$ ($\theta$ identifies the model point). Equation~\ref{eq:lambda} is approximated using Monte Carlo (MC) integration.  In the following, we describe the construction of the prior density and CMS likelihoods.

\subsection{Construction of the prior}
\label{sec:prior}
If the posterior density for a given parameter differs significantly from its prior density (or prior, for short), then we may conclude that the data have provided useful information about the parameter; otherwise, the converse is true. However, for such conclusions to be meaningful, it is necessary to start with a prior that encodes as much relevant information as
possible. In this study, the prior $p^\textrm{non-DCS}(\theta)$
encodes several constraints: the parameter space boundary, several
theoretical conditions, the chargino lifetimes, and most importantly
the constraints from non-DCS data, such as precision measurements and pre-LHC new physics searches.

The prior $p^\textrm{non-DCS}(\theta)$ is formulated as a product of four factors,
\begin{align}
	p^\textrm{non-DCS}(\theta) &\propto \left [ \prod_j L(D_j^\textrm{non-DCS} | \lambda_j(\theta)) \right] \,
		\cdot p(c\tau(\tilde{\chi}^\pm) < \textrm{10 mm}|\,\theta\,) \,
		 \cdot p(\textrm{theory}|\theta\,) \,
		 \cdot p_0(\theta).
		\label{eq:prior}
\end{align}
The initial prior $p_0(\theta)$ is taken to be uniform in the pMSSM sub-space (see Section \ref{sec:pmssm} for definitions of the parameters),
\begin{eqnarray}
	&-3 \le M_1, M_2 \le 3 ~\TeV,& \nonumber\\
	&0 \le M_3 \le 3 ~\TeV,			& \nonumber\\
	&-3 \le \mu \le 3 ~\TeV,		& \nonumber\\
	&0 \le m_{\rm A} \le 3 ~\TeV,			& \nonumber\\
	&2 \le \tan\beta \le 60,		& \nonumber\\
	&0 \le m_{{\tilde{\text{Q}}_{1,2}}}, m_{{\tilde{\text{U}}_{1,2}}}, m_{{\tilde{\text{D}}_{1,2}}}, m_{{\tilde{\text{L}}_{1,2}}}, m_{{\tilde{\text{E}}_{1,2}}}, m_{{\tilde{\text{Q}}_3}}, m_{{\tilde{\text{U}}_3}}, m_{{\tilde{\text{D}}_3}},m_{{\tilde{\text{L}}_3}}, m_{{\tilde{\text{E}}_3}} \le 3 ~\TeV,	& \nonumber\\
	&-7 \le A_{\text{t}}, A_{\text{b}}, A_\tau \le 7 ~\TeV,
\label{eq:subspace}
\end{eqnarray}
and the formally unbounded 
SM subspace defined by $m_{\rm t}$, $m_{\rm b}(m_{\rm
  b})$, and $\alpha_{\rm s}(m_{\rm Z})$; the non-DCS measurements, which are listed in Table~\ref{tab:preCMS}, constrain these SM parameters to narrow ranges.  A point in this sub-space is denoted by $\theta$.  
The sub-space defined in Eqs. (\ref{eq:subspace}) 
covers the 
phenomenologically viable parameter space for the LHC and 
is large enough to cover sparticle masses to which the LHC might
conceivably be 
ultimately sensitive.  The lower bound of 2 for $\tanb$ evades non-perturbative effects in the top-quark Yukawa coupling after evolution up to the GUT scale. These effects typically become a very serious issue for $\tanb\lsim 1.7$~\cite{Das:2000uk}.  
%{\color{red} TODO: SK, JG - Add a note on the range of $A_i$}. 
The term $p(\textrm{theory} |\,\theta\,)$  imposes the theoretical constraints listed at the end of Section~\ref{sec:pmssm}, while $p(c\tau(\tilde{\chi}^\pm)<10\text{ mm } |\, \theta\,)$ imposes the requirement that the chargino be prompt, that is, decays quickly. Both  $p(\textrm{theory} |\, \theta\,)$ 
and $p(c\tau(\tilde{\chi}^\pm)<10\text{ mm } |\,\theta\,)$ are unity if the
inequalities are satisfied and zero otherwise. 


The product of likelihoods $L(D^\mpreCMS|\lambda(\theta))$ in
Eq. (\ref{eq:prior}) over measurements $j$ is associated with \preCMS~ data, $D^\mpreCMS$,
which imposes constraints from precision measurements and a selection
of pre-LHC searches for new physics.

The measurements used and their associated likelihoods are listed in Table~\ref{tab:preCMS}.
We choose not to include data from DM experiments in the prior, in order to avoid bias from cosmological assumptions (e.g., DM density and distribution, assumption of one thermal relic, no late entropy production, etc.).
%\subsubsection{Sampling of prior}

Since the explicit functional dependence of the prior $p^\textrm{\preCMS}(\theta)$ on
$\theta$ is not available \emph{a priori}, but the predictions $\lambda(\theta)$ are available point by point, it is natural to represent the prior as a set of points sampled from it.  Owing to the complexity of the parameter space, the sampling is performed
using a Markov chain Monte Carlo (MCMC) 
method~\cite{MCMC1,MCMC2,MCMC3,MCMC4,Bayes:2}. 


% The \preCMS data included in the prior are shown in
% Table~\ref{tab:preCMS}.  All data except Higgs signal strenths $\mu_h$
% were used in the original MCMC scan.  However, measurements marked
% "reweight" in the last column were updated during this study, and the
% scanned points were reweighted to take into account the updated
% effects, as described in Appendix~\ref{sec:mcmcorigvars}, along with
% the original measurement values.


All data in Table~\ref{tab:preCMS} except the Higgs boson signal strengths $\mu_{\rm h}=\sigma/\sigma_{\text{SM}}$ were used in the
original MCMC scan. The $\mu_{\rm h}$ measurements were incorporated into the prior post-MCMC.    
A number of measurements, marked ``reweight''€™ in the last
column, were updated during the course of this study as new results
became available.  The weights, applied to the subset of scan points which were selected for simulation, were computed as the ratio of the likelihoods of the new measurements shown in
Table~\ref{tab:preCMS} to the previous measurements.    
%the original ones used in the MCMC sampling and the reweighting procedure are detailed in Appendix~\ref{sec:mcmcorigvars}. 

\input{pMSSMpaper/preCMStable}

For a given point $\theta$, the predictions $\lambda(\theta)$ --- including those needed
to calculate the likelihoods $L(D^\mpreCMS|\lambda(\theta))$ --- are obtained as follows. 
The physical masses and interactions are calculated 
using the SUSY spectrum generator {\sc SoftSUSY} 3.3.1~\cite{Allanach:2001kg},
with the input parameters $\theta$ defined at $M_{\rm SUSY}=\sqrt{m_{\tilde{\text{t}}_{1}}m_{\tilde{\text{t}}_{2}}}$. 
This calculation includes 1-loop corrections for sparticle masses and mixings, 
as well as 2-loop corrections for the small Higgs boson mass.
Low-energy constraints are calculated with {\sc SuperIso}
v3.3~\cite{Mahmoudi:2008tp}. {\sc micrOMEGAs} 2.4.5~\cite{Belanger:2001fz,Belanger:2004yn,Belanger:2008sj} is used 
to check the compatibility of pMSSM points with sparticle mass limits from LEP and other pre-LHC experiments. {\sc micrOMEGAs} is also used to compute the DM relic density, and the spin-dependent and spin-independent DM-nucleon scattering cross sections; these observables are not used in the construction of the prior, but we study how they are affected by the CMS searches. The program  {\sc SDECAY} 1.3~\cite{Muhlleitner:2003vg} is used to generate sparticle decay tables and 
{\sc HDECAY} 5.11~\cite{Djouadi:1997yw} to generate Higgs boson decay tables.
For evaluating the Higgs boson signal likelihood based on the latest ATLAS~\cite{ATLAS-CONF-2014-009}
and CMS~\cite{Khachatryan:2014jba} measurements, we use {\sc Lilith} 1.01~\cite{Bernon:2014vta,Bernon:2015hsa}, following the approach
explained in Section~2.3 of Ref.~\cite{Dumont:2013npa}. The experimental results used in {\sc Lilith} are the signal strengths
of the Higgs boson decay modes $Y=(\gamma\gamma,\,{\rm WW}^*,\,{\rm ZZ}^*,{\rm
  b}\bar {\rm b},\tau\tau)$ in terms of the primary Higgs boson production modes
gluon-gluon fusion (ggF), vector boson fusion (VBF), associated
production with a W or Z boson (Wh and Zh, commonly denoted as
Vh), and associated production with a top-quark pair (t$\bar{\text{t}}$h) as
published by ATLAS, CMS,
and Tevatron experiments.
When these signal strengths are given as 2-dimensional (2D) confidence level (CL) contours in, e.g., the
$\mu_{\rm ggF+tth}(Y)$ versus $\mu_{\rm VBF+Vh}(Y)$ plane, the
likelihood is approximated by fitting a 2D Gaussian function to the 68\%~CL
contour provided by the experiments.
For each experiment, a $\chi^2$ is computed using $- 2 \log L_Y
= \chi_Y^2$ for each decay mode $Y$, and the combined $\chi^2$ is
then obtained by summing over all the individual $\chi_Y^2$ values.
Additional information on signal strengths (and invisible decays) in
one dimension is included analogously, using the published likelihood function
when available or else the Gaussian approximation.
 
The uncertainty in the anomalous magnetic moment of the muon includes a component that accounts for theoretical uncertainties in the SUSY calculations.

The large window on the Higgs boson mass of 120--130 GeV covers the theoretical uncertainty in the Higgs boson
mass calculation in the MSSM. All tools use the SUSY Les Houches accord~\cite{Skands:2003cj} for
data entry and output.  Approximately 20 million points are sampled from $p^\textrm{non-DCS}(\theta)$ using multiple MCMC chains, but omitting the prompt chargino requirement. When that requirement is imposed, the number of sampled points is reduced by 30\%, and the fraction of bino-like LSPs (see Chapter \ref{chap:susy} Section \ref{sec:mssm}) is enhanced from about 40 to 50\%. A random subsample of 7200 points is selected for simulation studies. Given the large dimensionality of the model, this is a rather sparse scan. Nevertheless, the scan density is sufficient to learn much about the viability of the pMSSM model space. Distributions of model parameters in this subsample were compared with distributions from independent subsamples of similar size, as well as distributions from the original large sample, and consistency between distributions was observed within statistical uncertainties. 




\subsection{Incorporation of the CMS data}
\label{sec:cmslhd}
We consider the analyses given in Table~\ref{tab:CMS}, which explore final-states 
characterized by a variety of event-level observables:
the scalar sum of the transverse momenta of jets (\HT{}); the magnitude of the vector sum of 
the transverse momenta of final-state particles (\MET{} or \MHT{}); a measure of the transverse
mass~\cite{Lester:1999tx} in events in which two particles each decay to one invisible and one reconstructed particle (\MTtwo{}); the multiplicity of jets identified as originating from a b quark (b-jets); and a
range of lepton multiplicities, including opposite-sign (OS) and
like-sign (LS) lepton pairs.  Other analyses that were not included in this study but which may impose additional constraints on the model space include  searches for SUSY in the single lepton channel with one or multiple b-jets~\cite{Chatrchyan:2013iqa} and searches for top squark production~\cite{Chatrchyan:2013xna} in the single lepton channel. The searches together comprise hundreds of signal regions and address a large diversity of possible signal topologies.

\input{pMSSMpaper/CMStable} 

The CMS likelihoods $L(D^\mCMS|\,\theta)$ are calculated for each of these analyses (or combinations of analyses), using different forms of likelihood depending on the nature of the results that are available.
The first form of likelihood (\emph{counts}) uses observed counts,
$N$, and associated background estimates, $B \pm \delta B$; the second
($\chi^2$) uses profile likelihoods (see Section \ref{sec:freqcheck}), $T(\mu, \theta)$, where $\mu =
\sigma / \sigma^\textrm{SUSY}(\theta)$ is the signal strength modifier
and $\sigma$ and $\sigma^\textrm{SUSY}(\theta)$ are the observed and
predicted SUSY cross sections, respectively, while the third
(\emph{binary}) joins either of the first two kinds of result together
with a signal significance measure $Z$, and is used for combining
results from overlapping search regions. In the following, we describe the three forms of the
likelihood used and the signal significance measure $Z$.

%Details of these likelihoods and the signal significance measure are given in Appendix~\ref{sec:likelihoods}.

\paragraph*{Counts likelihood}
For a single-count analysis, the likelihood is given by  
\begin{equation}
L(D^\mCMS|\theta\,) = \int \textrm{Poisson}(N | s(\theta) + b) \, p(b|B, \delta B) db,
\label{eq:lhd_counts}
\end{equation}
where $N$ is the observed count,
$s(\theta)$ and $b$ are the expected number of signal and background counts, respectively,
and $B \pm\delta B$ is the estimated number of background event counts and its uncertainty.
The prior density for $b$, $p(b|B, \delta B)$, is modeled as a gamma density, 
$\textrm{gamma}(x;\alpha,\beta) = \beta \exp(-\beta x)  (\beta x)^{\alpha-1}/\Gamma(\alpha)$,
with $\alpha$ and $\beta$ defined such that the mode and variance of the gamma density are  $B$ and $(\delta B)^2$, respectively. 
%This likelihood provides an accurate description of statistical uncertainties and
%describes systematic uncertainties in an approximative way.
For analyses that yield multiple independent counts, the likelihood is
the product of the likelihoods of the individual counts. For analyses
with multiple counts, we treat
the background predictions for the different search regions as uncorrelated.  Systematic effects on the signal counts are taken into account by varying the signal yield by multiplying it with a signal strength modifier $\mu$ with values $1-\delta\mu, 1, 1+\delta\mu$, where $\delta\mu$ is the fractional value of the systematic uncertainty.

\paragraph*{$\chi^2$ likelihood}
This likelihood is used for CMS searches that provide profile
likelihoods, $T(\mu,\theta) \equiv
L(D^\mCMS|\mu,\theta,\hat\nu(\mu,\theta))$, for the signal strength
modifier $\mu$, where $\nu$ represents the nuisance parameters and
$\hat\nu(\mu,\theta)$ their conditional maximum likelihood
estimates. Taking $\hat\mu$ to be the signal strength modifier that
maximizes $T(\mu,\theta)$, it can be shown that the quantity $t =
-2\ln\left[T(1,\theta)/T(\hat\mu,\theta)\right]$ follows a $\chi^2$
density with one degree of freedom in the
asymptotic limit~\cite{Wilks:1938dza},
\begin{eqnarray}
L(D^\mCMS|\theta\,) & \approx &\exp(-t/2) / \sqrt{2\pi t}, 
  ~\label{eq:lhd_chi2}
\end{eqnarray}
which we adopt as the CMS likelihood in this case. The systematic uncertainties in the signal yield can again be incorporated with varying the values of $\mu$.
%This likelihood provides a good description of systematic and statistical uncertainties.

\paragraph*{$Z$-significance}
This study uses a signal significance measure defined by 
\begin{align}
  Z(\theta) = \textrm{sign} [\ln B_{10}(D, \theta )] \sqrt{2 | \ln B_{10}(D, \theta )|} ,
  \label{eq:Zsingle}
\end{align}
where 
\begin{equation}
  B_{10}(D, \theta) = \frac{L(D | \theta, H_1)}{L(D | H_0)} 
  \label{eq:B10}
\end{equation}
is the local Bayes factor for data $D$, at point $\theta$, and $L(D | \theta, H_1)$ and $L(D  | H_0)$
are the likelihoods for the signal plus background ($H_1$) and background only ($H_0$) hypotheses, respectively.  The function $Z(\theta)$ is a signed Bayesian analog of the frequentist ``$n$-sigma".
The case $Z \gg 0$ would indicate the presence of a signal 
at a significance of $Z$ standard deviations, while the case $Z \ll 0$ would indicate the absence of signal, i.e., an \emph{exclusion} at a significance of $Z$ standard deviations.  The $Z$-significance is the basis of the binary likelihood.

\paragraph*{Binary likelihood}
This likelihood is used for combining results from search regions in
which data may not be independent, for example, multiple counts from
overlapping search regions.  We first divide the data into subsets for
which either a count or $\chi^2$ likelihood can be calculated.  For
each subset $j$, with data $D_j$, we compute $Z_j(\theta)$ using Eq. 
(\ref{eq:Zsingle}).  An overall significance measure that includes all subsets under consideration is defined by
\begin{equation}
  Z(\theta) \equiv  Z_{j_{\rm max}}(\theta),
  \label{eq:Zmulti}
\end{equation}
where $j_{\rm max}$ is the index of the maximum element in the set \{$|Z_j(\theta)|$\}.
This quantity is used to define the binary likelihood as follows,
\begin{equation}
  L(D^\mCMS|\theta\,) =
  \begin{cases}
    1 & \text{if } Z(\theta) > -1.64, \\
    0 & \text{if } Z(\theta) \leq -1.64,
  \end{cases}
  \label{eq:lhd_binary}
\end{equation}
where $Z(\theta)=-1.64$ corresponds to the frequentist threshold for
exclusion at the 95\% CL. Systematic uncertainties are incorporated by computing each $Z_j(\theta)$ with varying  values of $\mu$, and using these recalculated $Z_j(\theta)$ to compute the binary likelihood.  
Although use of the binary likelihood entails a loss of information, it is a convenient approach in cases of non-disjoint data, where a proper likelihood calculation is not feasible without more information.  In this study, we use binary likelihoods for monojet searches, which have overlapping search regions, and for combining the 7 TeV, and 7$+$8 TeV results, where the analyses use non-disjoint data.

To compute likelihoods and $Z$-significances,  expected signal counts for
the search regions of each analysis are computed
for the 7200 pMSSM points. The simulated events for each model point, which were generated using {\sc pythia} 6.4~\cite{Sjostrand:2006za} and processed with the CMS fast detector simulation program~\cite{Abdullin:2011zz}, are passed through the analysis procedures in order to determine the counts.  For each pMSSM point, 10,000 events have been simulated.  

%%%%%%%%%%%%%%%%%%
% gluino mass
%%%%%%%%%%%%%%%%%%
\section{Results}
\label{sec:results}

We present the results of our study using three
different approaches to assess the implications of the analyses for the pMSSM parameter space.  In the first approach, we compare the distributions of the $Z$-significances.
In the second approach, we compare the prior and posterior densities of the pMSSM parameters.
In the third approach, we use a measure of the parameter space that remains after inclusion of the CMS search results.  This measure, the survival probability in a region $\Theta$ of the pMSSM parameter space, is defined by
\begin{equation}
  \frac{\int_\Theta p^\textrm{non-DCS}(\theta)H(Z(\theta) + 1.64)d\theta}{\int_\Theta p^\textrm{non-DCS}(\theta) \, d\theta},
  \label{eq:Survive}
\end{equation}
where $H$ is the Heaviside step function with a threshold value $Z = -1.64$, which
again is the threshold for exclusion at the 95\% CL. 

%%%%%%%%%%%%%%%%%%
% Z
%%%%%%%%%%%%%%%%%%
\subsection{Global significance}
Distributions of $Z$-significance are shown in Fig. \ref{fig:Z} for all the CMS
searches included in this study: 8~\TeV~searches, combinations of 7~\TeV~searches, and combinations of
7$+$8~\TeV~searches. The farther a $Z$ distribution is from zero, the
greater the impact of the analysis on the pMSSM parameter space.   As
noted in Section \ref{sec:anl}, negative and positive values indicate a preference for the background only ($H_0$) and the signal plus background ($H_1$) hypotheses, respectively.

All 8~\TeV~searches lead to distributions with negative tails,
indicating that each disfavors some region of the pMSSM parameter space.
The searches making the greatest impact are the \HT{}$+$\MHT{} and \MTtwo{}
searches, which disfavor a significant portion of the parameter space.
The \MTtwo{}, \HT{}$+$\MET{}$+$b-jets, EW, and OS dilepton searches,
which yield modest excesses over the SM predictions, have
$Z$-significances up to 4.

As expected, the combined 7$+$8~\TeV~result has a greater impact than any individual analysis. 
Overall, the impact of the 7~\TeV~combined result is relatively small as indicated by the high peak around zero.  The dip around zero in the combined 7$+$8~\TeV~distribution arises from the way we combine $Z$-significances. As expressed in Eq.~(\ref{eq:Zmulti}), the maximum $Z$-significance values are used in the combination.

%{\color{red} SS: Should we say something quantitative about what percent of the pMSSM space is excluded, etc here? {\color{blue} HP: No! This may open a can of worms!}}

\begin{figure}[t]
\centering
\resizebox{0.8\linewidth}{!}{
  \begin{tabular}{c}
  \incfigNum{(a)}{inclusive.pdf}
  \incfigNum{(b)}{hadExcl.pdf} \\
  \incfigNum{(c)}{leptonic.pdf} 
  \incfigNum{(d)}{combined.pdf}
  \end{tabular}
}
\vspace{1mm}
\caption{The distribution of model points, weighted by the \preCMS~ prior density, of the $Z$-significance for the individual 8~\TeV~searches (a--c), and for 7~\TeV~combined and 7$+$8~\TeV~combined searches (d). The leftmost bins contain the underflow entries.}
\label{fig:Z}
\end{figure}
\FloatBarrier
%%%%%%%%%%%%%%%%%%
% gluino mass
%%%%%%%%%%%%%%%%%%
\subsection{Impact on parameters}
Figure \ref{fig:mg} shows the impact of the CMS searches on our
knowledge of the gluino mass. Figures \ref{fig:mg} (a)-(d) show marginalized
distributions of the gluino mass.  Posterior distributions obtained
using three  signal strength modifier values $\mu = 0.5, 1.0, 1.5$
illustrate the effect of a $\pm50$\% systematic uncertainty in the
predicted SUSY signal yields.  Since the uncertainty in the signal efficiency typically varies between 10 and 25\%, and the uncertainty in the signal cross section ranges between 30 and 50\%, this prescription is considered to be conservative. Figure \ref{fig:mg} (a) shows the strong impact of
the hadronic analyses on the gluino mass distribution.  The
\HT{}$+$\MHT{} search strongly disfavors the region below 1200~\GeV,
while the \MTtwo{} search leads to a distribution with two regions of peaking probability, one at relatively low mass, around 600 to 1000~\GeV, and one
above 1200~\GeV.  In Fig. \ref{fig:mg} (b) we observe that the other hadronic
analyses also disfavor the low-mass region, though to a lesser degree,
 and two of these analyses (the \HT{}$+$\MET{}$+b$-jets and the
 hadronic third generation) also exhibit secondary
 preferred regions around 1100~\GeV, while Fig. \ref{fig:mg} (c) shows that the EW, OS dilepton, and LS dilepton searches have little impact on the gluino mass distribution.
Figure \ref{fig:mg} (d) compares the  prior distribution to posterior distributions after inclusion of the combined 7~\TeV~and combined 7$+$8~\TeV~data.  The 7~\TeV~data already have sufficient sensitivity to exclude much of the low-mass gluino model space, and the 8~\TeV~data further strengthen this result.

 The enhancements induced by the hadronic
searches in the 800\textendash1300~\GeV~ range disappear in the combination
since the observed excesses driving the enhancements are not
consistent with a single model point or group of model points.
%The binary likelihood combination results in an ascending probability density.
%{\color{red} HP: It is not clear what point we wish to make with the last sentence}.
%This is consequence of the important drawback, loss of information, of the binary likelihood method used to calculate the CMS likelihood for the distributions for combinations of CMS searches.


\begin{figure}[t]
    \sixpackNum{mg}
\vspace{1mm}
    \caption{\captionOneD{gluino mass}{gluino mass}}
    \label{fig:mg}
\end{figure}

Figure \ref{fig:mg} (e) shows the survival probability (Eq. \ref{eq:Survive}) as a function of gluino mass
for the combined 7~\TeV, and 7$+$8~\TeV~results. 
The CMS searches exclude all the pMSSM points with a gluino mass below 500~\GeV, and can probe scenarios up to the highest masses covered in the scan.  As may be expected, masses of order 3~\TeV~are not probed directly but rather through the production of lighter particles in the model.   
Finally, Fig. \ref{fig:mg} (f) shows the $Z$-significance versus gluino mass.  A
slight negative correlation for positive $Z$ values and gluino masses
is observed below 1200~\GeV; $Z$ declines slightly as mass
increases, which indicates that some small excesses of events observed by the various searches are consistent with models with light gluinos.  

%%%%%%%%%%%%%%%%%%
% squark LCSP mass
%%%%%%%%%%%%%%%%%%

Figures \ref{fig:mq} and~\ref{fig:mLCSP} similarly summarize the impact
of searches on the first- and second-generation left-handed up squark mass and the mass of the lightest colored SUSY particle (LCSP), respectively.  The picture is similar to that for the gluino mass.  For both $\suL$ and the LCSP, the \MTtwo{} search shows a preference for masses from 500 to 1100~\GeV.  The overall impact of the searches on $\suL$ is less than the impact on the gluino mass owing to the more diverse gluino decay structure that can be accessed by a greater number of searches.  For the LCSP, the overall impact is the least  because the LCSP has the fewest decay channels; nevertheless CMS searches exclude about 98\% of the model points with an LCSP mass below 300~\GeV; in the surviving 2\% of these model points (6 points), the LCSP is always the $\tilde{d}_{\rm R}$.  We also see that the searches can be sensitive to scenarios with LCSP masses up to $\sim$1500~\GeV.  Again we find that the
Higgs boson results  make a negligible contribution. In each case we find a negative correlation between the $Z$-significance and the sparticle mass for positive $Z$ values and masses below 1200~\GeV; this is most pronounced for the LCSP.

\begin{figure}[t]
    \sixpackNum{muL}
    \vspace{1mm}
    \caption{\captionOneDReduced{$\suL$ mass (equivalently, the $\scL$ mass)}{$\suL$ mass}}
    \label{fig:mq}
\end{figure}

\begin{figure}[t]
    \sixpackNum{mLCSP}
    \vspace{1mm}
    \caption{\captionOneDReduced{mass of the lightest colored SUSY particle (LCSP)}{LCSP mass}}
    \label{fig:mLCSP}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%
% stop mass
%%%%%%%%%%%%%%%%%%%%%%%

Figure \ref{fig:mt1} illustrates what information this set of searches provides about the mass of the lightest top squark $\stl$.   
The difference between the prior and posterior distributions is minor. The reason is that the low-energy measurements such as 
 the b $\to$ s $\gamma$ branching fraction (see 
Table \ref{tab:preCMS}) impose much stronger constraints on the mass of the $\stl$ than do the analyses. 
This is not to say the CMS analyses are insensitive to top squark masses. The posterior distribution for the \MTtwo{} 
search exhibits an enhancement at $m_{\stl}<1~\TeV$ relative to the \preCMS~distribution. This enhancement does not 
appear in the combined posterior density because is suppressed by observations of other more sensitive searches, which is a good illustration of the importance of doing global analyses.  
 In the distribution of $m_{\stl}$ versus $Z$, the positive (negative) $Z$ values have a slight negative (positive) 
correlation with the $\stl$ mass below 1~\TeV, indicating that the CMS analyses have some 
direct sensitivity to top squarks with masses up to 1~\TeV. The overall conclusion is that light top squarks 
with masses of the order of 500~\GeV~ cannot be excluded.
 
\begin{figure}[t]
    \sixpackNum{mt1}
    \vspace{1mm}
    \caption{\captionOneDReduced{$\stopi$ mass}{$\stopi$ mass}}
    \label{fig:mt1}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%
% mz1 and mLNDw
%%%%%%%%%%%%%%%%%%%%%%%

Turning now to the EW sector, we first show, in
Fig. \ref{fig:mz1}, the effect of the CMS data on our knowledge of the
mass of the lightest neutralino $\chiz$.  We see that the hadronic 
searches disfavor low $\chiz$ masses; the hadronic
searches targeting specific topologies also have an effect, although
smaller, and the leptonic searches have a marginal impact.  The
7$+$8~\TeV~combined distribution is very similar to the \MTtwo{}
distribution, especially in the lower mass region, indicating that this search is the most sensitive to the
$\chiz$ mass.  The main constraint 
on the $\chiz$ mass arises indirectly through correlations with other sparticle masses.  Since $\chiz$ is
the LSP, its mass is constrained by the masses of
the heavier sparticles.  As CMS searches push the probability
distributions for the colored particles to higher values, more phase
space opens for $\chiz$ and the $\chiz$ distributions shift to higher
values.  The survival probability distribution shows that no $\chiz$
mass is totally excluded at the 95\% CL by CMS.  In general, the nonexcluded points with light $\chiz$ are those with heavy colored sparticles.  The fact that the survival probability decreases below a $\chiz$ mass of $\sim$700~\GeV~ shows that CMS searches are sensitive up to this mass value.
%{\color{red} Question from JG: What is the definition of sensitive, and why 700~\GeV~?}
The Higgs boson data disfavor neutralino masses below about 60~\GeV, that is,
the mass range in which invisible decays
$h\to\tilde\chi^0_1\tilde\chi^0_1$ could occur; this is visible in the
first bin in Fig. \ref{fig:mz1} (d) (see Ref.~\cite{Bernon:2014vta}).

\begin{figure}[t]
    \sixpackNum{mz1}
    \vspace{1mm}
    \caption{\captionOneDReduced{$\chiz$ mass}{$\chiz$ mass}}
    \label{fig:mz1}
\end{figure}

In the MSSM, the lightest chargino becomes degenerate with the lightest neutralino when 
$|M_1| \geq \min(|M_2|,|\mu|)$.  
Therefore, we define the lightest non-degenerate (LND) chargino as
\begin{equation}
    \mathrm{LND~}{\chi^\pm} =
    \begin{cases}
        \tilde{\chi}^\pm_1 & \mbox{if~~~} |M_1| < \min(|M_2|,|\mu|) \\
        \tilde{\chi}^\pm_2 & \mbox{if~~~} |M_1| > \min(|M_2|,|\mu|).
    \end{cases}
\end{equation}
Figure \ref{fig:mLNDw} summarizes what information has been gained about the mass of the 
LND chargino. 
%{\color{red} SS: Sabine or Jack, is the LND content ok?}.
Again, the impact of the CMS searches is found to be rather limited and no chargino mass
can be reliably excluded.
%We note the rather limited impact of the CMS data.
It is worth noticing the impact of the leptonic searches.
In Fig. \ref{fig:mLNDw} (c), the distributions differ from the \preCMS~ distribution,
while these searches have negligible impact on most of the other  SUSY observables and parameters. We also note that the survival probability is lowest in the first bin where the LND mass is between 0 and 200~\GeV, but a small percentage of points still survive.

\begin{figure}[t]
  \sixpackNum{mLNDw}
  \vspace{1mm}
  \caption{\captionOneDReduced{the mass of the lightest non-degenerate (LND) chargino}{LND $\widetilde{\chi}^\pm$ mass} }
  \label{fig:mLNDw}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%
% xsect
%%%%%%%%%%%%%%%%%%%%%%%

A more generic view is possible by looking at the overall CMS impact on the inclusive SUSY production cross section for 8~\TeV, which is shown in Fig. \ref{fig:xsect}. 
The most probable total sparticle cross section in \preCMS~ prior is
approximately 100\,$\fb$; the low tail of this distribution is shaped by the upper limits on the masses of sparticles in the prior. The effect of the CMS SUSY searches is to reduce this
value by an order of magnitude.  The \HT{}$+$\MHT{} search
has the largest individual contribution to this because of its ability to address a great diversity of final states comprising different sparticle compositions.  The survival probability distribution confirms that CMS is sensitive to SUSY scenarios with total cross sections as low as 1\,$\fb$. 
%\sigma^{8~\TeV}_{\rm SUSY}
\begin{figure}[t]
    \sixpackNum{log10_xsect_8TeV}
    \vspace{1mm}
    \caption{\captionOneDReduced{the logarithm of the cross
        section for inclusive sparticle production in 8~TeV pp
        collisions, $\log_{10}(\sigma^{8~\TeV}_{\rm SUSY})$,}{$\log_{10}(\sigma^{8~\TeV}_{\rm SUSY})$} In plot (d), the apparent enhancement of the left tail of the posterior density with respect to the prior is due to the suppression of the right tail and an overall renormalization. }
    \label{fig:xsect}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%
% more 1D
%%%%%%%%%%%%%%%%%%%%%%%

In Fig. \ref{fig:more1D}, the  \preCMS~ and post-CMS distributions are
compared after 7 and 7$+$8~\TeV~data for several other important
observables.  We first note that the impact of the CMS data on the
first and second generation right-handed up squarks is lower than on the
corresponding left-handed up squarks. This is because left-handed up squarks in
the MSSM form doublets with mass-degenerate left-handed down squarks, while
the right-handed up and down squarks are singlets and their
masses are unrelated.  Therefore, for the left-handed up squarks, the CMS
sensitivity for a given mass is increased by the left-handed down squarks,
which have the same mass.  We also observe a mild impact on the bottom
squark mass, where CMS disfavors masses below 400~\GeV.  The CMS
searches also have some sensitivity to the selectron and stau masses,
which comes from the leptonic searches.  The impact on $\chitz$ and
$\chipm$ masses is relatively larger, mostly due to the dedicated EW
analyses. The CMS SUSY searches have no impact on the masses of the light and heavy pseudoscalar Higgs
bosons. The preference of the Higgs data for negative values of the higgsino mass parameter $\mu$ comes primarily from the fact that the measured signal 
strength normalized to its SM value for Vh$\to$b$\bar{\text{b}}$ (where V is a W or a Z boson) is currently slightly below one. In a SUSY model, this requires that radiative corrections reduce the bottom Yukawa coupling, thereby creating a preference for $\mu<0$~\cite{Dumont:2013npa}. The $\tan\beta$ distribution is largely unaffected by both the CMS SUSY searches and the current Higgs boson data evaluated via {\sc Lilith} 1.01. 

We also investigate the impact of CMS searches on some observables
related to dark matter. Figure~\ref{fig:more1D_dm}  shows distributions of the
dark matter relic density, the spin-dependent (SD) direct detection cross section,
and spin-independent (SI) direct detection cross section. In Fig.~\ref{fig:more1D_dm} (a),
 the relic density is seen to take on a bimodal probability density.
The lower peak corresponds primarily to model points with bino-like LSPs,
and the upper peak is mainly due to points with wino- and higgsino-like LSPs. The combined CMS searches lead to a noticeable enhancement of the lower peak. In Fig.~\ref{fig:more1D_dm} (b) and (c), minor differences are seen between the prior and posterior densities for the direct detection cross section.
%{\col{red} TODO - SS: Sabine, I leave this to you.}

\begin{figure}[p]
\centering
\makebox[.33\textwidth][c]{
\incfigNum{(a)}{combined_higgs/combined_higgs_muR_rebin.pdf}
\incfigNum{(b)}{combined_higgs/combined_higgs_mb1_rebin.pdf}
\incfigNum{(c)}{combined_higgs/combined_higgs_meL_rebin.pdf}
}\\
\makebox[.33\textwidth][c]{
\incfigNum{(d)}{combined_higgs/combined_higgs_mtau1_rebin.pdf}
\incfigNum{(e)}{combined_higgs/combined_higgs_mz2_rebin.pdf}
\incfigNum{(f)}{combined_higgs/combined_higgs_mw1_rebin.pdf}
}\\
\makebox[.33\textwidth][c]{
\incfigNum{(g)}{combined_higgs/combined_higgs_mu.pdf}
\incfigNum{(h)}{combined_higgs/combined_higgs_tanb_rebin.pdf}
\incfigNum{(i)}{combined_higgs/combined_higgs_mA_pole_rebin.pdf}
}
\vspace{1mm}
\caption{Comparison of prior and posterior distributions after several combinations of data from the CMS searches for the
$\suR,\scR$ mass, $\sb_{1}$ mass, $\seL,\smuL$ mass, $\stauOne$ mass, $\chitz$ mass, $\chipm$ mass, the higgsino mass parameter $\mu$, $\tanb$, and A mass.}
\label{fig:more1D}
\end{figure}

\begin{figure}[htbp]
  \centering
  \makebox[.33\textwidth][c]{
  \incfigNum{(a)}{combined_higgs/combined_higgs_log10_omgh2_rebin.pdf}
  \incfigNum{(b)}{combined_higgs/combined_higgs_log10_sigSD_rebin.pdf}
  \incfigNum{(c)}{combined_higgs/combined_higgs_log10_sigSI_rebin.pdf}}\\
        \vspace{1mm}
    \caption{Comparison of prior and posterior distributions after several
  combinations of data from the CMS searches for $\Omega_{\tilde{\chi}^{0}_{1}}$, $\xi\sigma^{\text{SD}}(p\tilde{\chi}_{1}^{0})$, and $\xi\sigma^{\text{SI}}(p\tilde{\chi}_{1}^{0})$.}
    \label{fig:more1D_dm}
\end{figure}
\FloatBarrier

\subsection{Correlations among pMSSM parameters}
A virtue of high-dimensional models like the pMSSM is that they
enable the examination of correlations among parameters not 
possible in the context of more constrained models.

Figure \ref{fig:twoD} compares marginalized distributions in two dimensions of \preCMS~ (left) to post-CMS distributions (middle), and also shows the post-CMS to \preCMS~ survival probability (right) for several observable pairs.  The first two rows of distributions show that the CMS impact on our knowledge of 
the $\chiz$ mass is strongly correlated with the gluino or the LCSP mass.  Since $\chiz$ is the LSP,  light colored particles imply a light $\chiz$.
% and therefore the exclusion of scenarios with light colored particles.  
Consequently, the disfavoring of light colored sparticles implies the disfavoring of a light $\chiz$.  In the last row, it is seen that the $\chiz$ mass is correlated most strongly with the cross section and that light $\chiz$ LSPs are indeed disfavored for the reason just given.  
We note, however, that scenarios with $\chiz$ masses around 100~\GeV~
can still survive even though they have cross sections above 1\,pb! These and other high cross section model points are discussed in Section \ref{sec:unexplored}.
In the third row, we show the probability distributions and survival
probability for $\chiz$ versus $\stl$ mass.  Although the
post-CMS probabilities shift towards higher values, the survival
probabilities never really go down to zero.  Although current simplified model
scenarios exclude large parts of the $\stl$-$\chiz$ plane, we see that
pMSSM scenarios with relatively low $\stl$ masses (500~\GeV) are
not significantly disfavored by the CMS searches. 

\begin{figure}[p]
  \centering
  \figTwoD{mg_rebin_VS_mz1_rebin}\\
  \figTwoD{mLCSP_rebin_VS_mz1_rebin}\\
    \figTwoD{mt1_rebin_VS_mz1_rebin}\\
  \figTwoD{log10_xsect_8TeV_rebin_VS_mz1_rebin}
\vspace{1mm}
  \caption{Marginalized \preCMS~ distributions (first column),
    compared with posterior distributions (second column)
    and survival probabilities (third column) after inclusion of the combined CMS searches,
    are shown for the
    $\chiz$ mass versus gluino mass (first row), the LCSP mass
    (second row), the top squark mass (third row),  and the
    logarithm of the cross section for inclusive sparticle production at 8~\TeV~(bottom row).
  }
  \label{fig:twoD}
\end{figure}

As is true of any Bayesian analysis, the results depend both on the likelihood and the prior. Studies were therefore performed to assess how the conclusions would change if a 
different choice of initial prior had been made. A log-uniform prior ($p_0(\theta)$ in Eq. \ref{eq:prior}) is found to yield posterior densities very similar to those using the uniform prior. The most significant exception are 
the densities for the masses of the $\chiz$ and  $\chipm$, which are shifted 10\textendash20\% 
toward higher values with respect to the densities derived from the
uniform prior. It is found that the marginalized 
likelihood distributions are consistent with the profile likelihoods, suggesting that a 
frequentist analysis based on the profile likelihoods would yield similar conclusions. More details are given in the next section.
\FloatBarrier


\section{Change of prior}
For any choice of prior, there will be some parameterization in which the prior density is constant (that is, uniform or flat). The difficult question to answer is: in which parameterization ought the prior density be constant? In the pMSSM paper, the ur-prior (coined by Glen Cowan from the German prefix {\it ur} meaning original or primitive), is taken to be uniform in a physically motivated parameterization. However, \emph{a priori} it is not clear that this
is the parameterization in which the prior should be flat.  
Foregoing a discussion of how best to choose a parametrization,  we examine how our results are affected when the choice of ur-prior is changed.

Figures \ref{fig:mg_prepost}-\ref{fig:mApole} show the prior and posterior density projections onto a suite of parameters presented in the paper \cite{pMSSMpaper}, given the choice of a flat prior (red) and a prior proportional to the product of the log of each parameter (blue), which we refer to as the log prior. The main conclusions of the paper stand with respect to this change, namely that
\begin{itemize}
\item pMSSM points with gluino masses below 500 GeV are excluded, but a small number points with 550 GeV gluinos survive (Fig. \ref{fig:mg});
\item the probability density of the light top squark mass is not significantly shifted by the CMS analyses (Fig. \ref{fig:mt1});
\item no LSP mass can be excluded (Fig. \ref{fig:mz1}), and
\item the most probable value (MPV) of the signal cross section has been pushed down by a factor of 10 (Fig. \ref{fig:xsect}).
\end{itemize}
The posterior MPVs for most parameters agree within 5\% between the flat and log priors. The most significant difference is in the impact on the LSP mass, where the log prior prefers slightly larger values of the LSP mass (Fig. \ref{fig:mz1}). This is because the LSP in general exhibits a high density in the low mass region, and this region is suppressed due to the log Jacobian.  The result is that the bulk of the prior and posterior is shifted down.


\begin{figure}[h]
\centering
\subfloat[]{
\includegraphics[width=0.5\linewidth]{figures/pMSSMpaper/Prior/mgprepost.pdf}
}
\subfloat[]{
\includegraphics[width=0.5\linewidth]{figures/pMSSMpaper/Prior/mgratio.pdf}
}\\
\subfloat[]{
\includegraphics[width=0.5\linewidth]{figures/pMSSMpaper/Prior/muLprepost.pdf}
}
\subfloat[]{
\includegraphics[width=0.5\linewidth]{figures/pMSSMpaper/Prior/muLratio.pdf}

}
\caption{Left: posterior/prior of $m_{\tilde{\text{g}}}$ (top) and $m_{{\text{U}_{\text{L}}}}$ (bottom). Right: Ratio of the posterior to the prior of $m_{\tilde{\text{g}}}$ (top) and $m_{{\text{U}_{\text{L}}}}$ (bottom).}
\label{fig:mg_prepost}
\end{figure}

\begin{figure}[h]
\centering
\subfloat[]{
\includegraphics[width=0.5\linewidth]{figures/pMSSMpaper/Prior/muRprepost.pdf}
}
\subfloat[]{
\includegraphics[width=0.5\linewidth]{figures/pMSSMpaper/Prior/muRratio.pdf}
}\\
\subfloat[]{
\includegraphics[width=0.5\linewidth]{figures/pMSSMpaper/Prior/mt1prepost.pdf}
}
\subfloat[]{
\includegraphics[width=0.5\linewidth]{figures/pMSSMpaper/Prior/mt1ratio.pdf}
}
\caption{Left: posterior/prior of $m_{\text{U}_R}$ (top) and $m_{\tilde{\text{t}}_1}$ (bottom). Right: Ratio of the posterior to the prior of $m_{\text{U}_R}$ (top) and $m_{\tilde{\text{t}}_1}$ (bottom).}
\label{fig:mApole}
\end{figure}


\begin{figure}[h]
\centering
\subfloat[]{
\includegraphics[width=0.5\linewidth]{figures/pMSSMpaper/Prior/mz1prepost.pdf}
}
\subfloat[]{
\includegraphics[width=0.5\linewidth]{figures/pMSSMpaper/Prior/mz1ratio.pdf}
}\\
\subfloat[]{
\includegraphics[width=0.5\linewidth]{figures/pMSSMpaper/Prior/mb1prepost.pdf}
}
\subfloat[]{
\includegraphics[width=0.5\linewidth]{figures/pMSSMpaper/Prior/mb1ratio.pdf}

}
\caption{Left: posterior/prior of $m_{\tilde{\chi}^{0}_{1}}$ (top) and $m_{\tilde{\text{b}}_1}$ (bottom). Right: Ratio of the posterior to the prior of $m_{\chi^{0}_{1}}$ (top) and $m_{\tilde{\text{b}}_1}$ (bottom).}
\label{fig:mb1ratio}
\end{figure}
\FloatBarrier

\begin{figure}[h]
\centering
\subfloat[]{
\includegraphics[width=0.5\linewidth]{figures/pMSSMpaper/Prior/Ml1prepost.pdf}
}
\subfloat[]{
\includegraphics[width=0.5\linewidth]{figures/pMSSMpaper/Prior/Ml1ratio.pdf}
}\\
\subfloat[]{
\includegraphics[width=0.5\linewidth]{figures/pMSSMpaper/Prior/mtau1prepost.pdf}
}
\subfloat[]{
\includegraphics[width=0.5\linewidth]{figures/pMSSMpaper/Prior/mtau1ratio.pdf}

}
\caption{Left: posterior/prior of $m_{\tilde{\text{l}}_1}$ (top) and $m_{\tilde{\tau}_1}$ (bottom). Right: Ratio of the posterior to the prior of $m_{\tilde{\text{l}}_1}$ (top) and $m_{\tilde{\tau}_1}$ (bottom).}
\label{fig:mg_muL}
\end{figure}


\begin{figure}[h]
\centering
\subfloat[]{
\includegraphics[width=0.5\linewidth]{figures/pMSSMpaper/Prior/mw1prepost.pdf}
}
\subfloat[]{
\includegraphics[width=0.5\linewidth]{figures/pMSSMpaper/Prior/mw1ratio.pdf}
}\\
\subfloat[]{
\includegraphics[width=0.5\linewidth]{figures/pMSSMpaper/Prior/mApoleprepost.pdf}
}
\subfloat[]{
\includegraphics[width=0.5\linewidth]{figures/pMSSMpaper/Prior/mApoleratio.pdf}
}
\caption{Left: posterior/prior of $m_{\tilde{\chi}_{1}^{\pm}}$ (top) and $m_{A}$(pole) (bottom). Right: Ratio of the posterior to the prior of $m_{\tilde{\chi}_{1}^{\pm}}$ (top) and $m_{A}$(pole) (bottom).}
\label{fig:mg_muL}
\end{figure}
\FloatBarrier

\section{Profile vs Marginal likelihoods}
\label{sec:freqcheck}
Experience suggests that when profile and marginal likelihoods are in approximate agreement, the conclusions obtained via frequentist and Bayesian methods  approximately agree. Therefore, it is
instructive to examine the profile likelihoods. To do so, 
we construct a smooth analytic expression for the 19-D non-DCS likelihood. The non-DCS likelihood can be factorized as a separable component equal to the product of 19 1-D functions, and a correction function that accounts for the statistical dependencies among parameters, which, for simplicity, we shall refer to using the slightly imprecise term ``correlation":
\begin{equation}
P(D^{\rm non\textendash DCS}|\vec{\theta}\ ) = {\rm C}(\vec{\theta}\ ) \cdot \prod_{i}^{19}f(\theta_{i}),
\label{eq:Likelihood}
\end{equation}
where $\vec{\theta}$ is a vector of the 19 pMSSM parameters of which $\theta_i$ is the $i$th element, the $f(\theta_{i})$ functions are the 1-D non-DCS marginal likelihoods,
\begin{equation}
f(\theta_i) = \int_1 d\theta_1 \cdots \int_j d\theta_j \cdots P(D^{\rm non\textendash DCS}|\vec{\theta}\ ) \, \pi_F(\vec{\theta}\ ) \quad j \neq i,
\end{equation}
 using a flat ur-prior, $\pi_F(\vec{\theta}\ )$, and C($\vec{\theta}$\ ) encodes the correlations between the pMSSM parameters induced by the non-DCS measurements and constraints. 

The 1-D functions, $f(*)$, are estimated using TMVA regression methods~\cite{Hocker:2007ht}. For each regression, the swarm of points that constitute a discretized approximation to the non-DCS likelihood is projected onto a single pMSSM parameter, forming a 1-D histogram. The heights of the histogram bins are taken as the target, and the centers of the bins are taken as the input variable. A multi-layer perceptron (MLP) is trained using the call

\begin{quote}
\texttt{TMVA::Factory::BookMethod}
\texttt{factory.BookMethod( TMVA.Types.kMLP, "MLP",\\
        `!H:!V:VarTransform=Norm:NeuronType=tanh:NCycles=5000:\\
        HiddenLayers=N+5,N+2:TestRate=6:TrainingMethod=BFGS:Sampling=0.2:'+\\
        `SamplingEpoch=0.985:ConvergenceImprove=1e-6')}\\
\end{quote}
The resulting $f(\theta_i) \equiv$ MLP($\theta_i$) functions are shown in Figures \ref{fig:KdeMlp}, along with the target histograms. The MLP approximations are seen to be reasonable.

The correlation function C($\theta$) is estimated using a multivariate classifier whose training sample consists of signal events corresponding to the original scan points, and background events consisting of pseudo-data generated from a sampling of the separable regression product. The classifier is an MLP whose output (see Figure \ref{fig:Classifier}) can be interpreted generally as
\begin{equation}
D = \frac{p(\vec{\theta} | {\rm s})}{p(\vec{\theta} | {\rm s})+p(\vec{\theta} | {\rm b})},
\label{eq:mlp}
\end{equation}
given that the training was performed with equal numbers of signal (s) and background (b) events. In our case, the output is
\begin{equation}
D = \frac{p(D^{\rm non-DCS}|\vec{\theta}\ )}{p(D^{\rm non-DCS}|\vec{\theta}\ )+ \prod_{i}^{19}f(\theta_{i})}.
\label{eq:MLP}
\end{equation}
Rearranging Eq.(\ref{eq:MLP}) gives
\begin{equation}
P(D^{\rm non-DCS}|\vec{\theta}\ ) = \frac{D}{1-D}\prod_{i}^{19}f(\theta_{i}),
\label{eq:Like}
\end{equation}
and the correlation function (Eq.(\ref{eq:Likelihood})) is identified as
\begin{equation}
{\rm C}(\vec{\theta}\ ) = \frac{D}{1-D}.
\end{equation}
The 1-D profile likelihoods were derived by maximizing Equation \ref{eq:Like} with respect to the $n-1=18$ parameters. 

Comparisons between the profile likelihoods and the 1-D non-DCS  marginal likelihoods are given in Figures \ref{fig:PandP1}-\ref{fig:PandP4}.  The comparison shows general agreement to within $\sim$10\%, with a couple of exceptions. The first notable difference is in the bino mass Lagrangian parameter $M_1$, where the profile likelihood is relatively enhanced at large absolute values of $M_1$. If the LSP is bino-like,  confidence levels (CLs) based on the posterior densities would tend to under-exclude LSP masses; however, no LSP mass is excluded by the Z-significance, and so this does not alter the statement about LSPs made in the paper \ref{bib:pMSSM}. Finally, the trilinear coupling $A_t$ appears to have a roughly 30\% enhancement in the negative region for the likelihood with respect to the marginal likelihood. However, the paper makes no explicit statement about the impact of CMS analysis on the trilinear couplings. The otherwise general similarity of the two sets suggests that a frequentist analysis based on the profile likelihoods would yield conclusions consistent with those in the CMS pMSSM paper.  The Z-significance is a mapping of the Bayes factor that roughly maps to a frequentist n-sigma, the only difference being that rather than maximizing the likelihood to eliminate nuisance parameters, the likelihood is marginalized. 

\renewcommand*\thesubfigure{\arabic{subfigure}}
\begin{figure}[htbp]
\centering
\hspace{-8mm}
\subfloat[]{
  \includegraphics[width=50mm]{figures/pMSSMpaper/Prior/MLP/trainedRegression1_M1}
}
\hspace{-8mm}
\subfloat[]{
  \includegraphics[width=50mm]{figures/pMSSMpaper/Prior/MLP/trainedRegression1_M2}
}
\hspace{-8mm}
\subfloat[]{
  \includegraphics[width=50mm]{figures/pMSSMpaper/Prior/MLP/trainedRegression1_M3}
}
\hspace{-8mm}
\subfloat[]{
  \includegraphics[width=50mm]{figures/pMSSMpaper/Prior/MLP/trainedRegression1_mu}
}
\hspace{-8mm}
\subfloat[]{   % ???
  \includegraphics[width=50mm]{figures/pMSSMpaper/Prior/MLP/trainedRegression1_mA_pole}
}
\hspace{-8mm}
\subfloat[]{
  \includegraphics[width=50mm]{figures/pMSSMpaper/Prior/MLP/trainedRegression1_tanb}
}
\hspace{-8mm}
\subfloat[]{
  \includegraphics[width=50mm]{figures/pMSSMpaper/Prior/MLP/trainedRegression1_Mq1}
}
\hspace{-8mm}
\subfloat[]{
  \includegraphics[width=50mm]{figures/pMSSMpaper/Prior/MLP/trainedRegression1_Mq3}
}
\hspace{-8mm}
\subfloat[]{
  \includegraphics[width=50mm]{figures/pMSSMpaper/Prior/MLP/trainedRegression1_Mu1}
}
\hspace{-8mm}
\subfloat[]{
  \includegraphics[width=50mm]{figures/pMSSMpaper/Prior/MLP/trainedRegression1_Mu3}
}
\hspace{-8mm}
\subfloat[]{
  \includegraphics[width=50mm]{figures/pMSSMpaper/Prior/MLP/trainedRegression1_Md1}
}
\hspace{-8mm}
\subfloat[]{
  \includegraphics[width=50mm]{figures/pMSSMpaper/Prior/MLP/trainedRegression1_Md3}
}
\hspace{-8mm}
\subfloat[]{
  \includegraphics[width=50mm]{figures/pMSSMpaper/Prior/MLP/trainedRegression1_Ml1}
}
\hspace{-8mm}
\subfloat[]{
  \includegraphics[width=50mm]{figures/pMSSMpaper/Prior/MLP/trainedRegression1_Ml3}
}
\hspace{-8mm}
\subfloat[]{
  \includegraphics[width=50mm]{figures/pMSSMpaper/Prior/MLP/trainedRegression1_Mr1}
}
\hspace{-8mm}
\subfloat[]{
  \includegraphics[width=50mm]{figures/pMSSMpaper/Prior/MLP/trainedRegression1_Mr3}
}
\hspace{-8mm}
\subfloat[]{
  \includegraphics[width=50mm]{figures/pMSSMpaper/Prior/MLP/trainedRegression1_At}
}
\hspace{-8mm}
\subfloat[]{
  \includegraphics[width=50mm]{figures/pMSSMpaper/Prior/MLP/trainedRegression1_Ab}
}
\hspace{-8mm}
\subfloat[]{
  \includegraphics[width=50mm]{figures/pMSSMpaper/Prior/MLP/trainedRegression1_Al}
}
\caption{The results of the 19 MLP regressions on the pMSSM parameters. }
\label{fig:KdeMlp}
\end{figure}
\FloatBarrier

\begin{figure}[h]
\centering
  \includegraphics[width=0.6\linewidth]{figures/pMSSMpaper/Prior/CompareFrequentist/figpmssmnettrain}
\caption{The output of the MLP used to derive the correction function. The red distribution is the original set of pMSSM points and the blue distribution is the set generated by a random sampling of the separable likelihood function. }
\label{fig:Classifier}
\end{figure}

%\begin{figure}[h]
%\centering
%\subfloat[]{
%  \includegraphics[width=0.9\linewidth]{figures/pMSSMpaper/Prior/CompareFrequentist/ParCorCorrFunction.pdf}
%  }
%\caption{A parallel coordinates plot of showing the correlation function D/(1-D) and its dependence on a few pMSSM parameters. The correlation function is not dominantly correlated with any one variable. The pMSSM parameters have each been normalized to a unit interval.}
%\label{fig:LlhdVs19dMva}
%\end{figure}


\renewcommand*\thesubfigure{\arabic{subfigure}}
\begin{figure}[htbp]
\centering
\hspace{2mm}
\subfloat[]{
  \includegraphics[width=65mm]{figures/pMSSMpaper/Prior/CompareFrequentist/CompareProfileLhdWithPriorM1}
}
\hspace{2mm}
\subfloat[]{
  \includegraphics[width=65mm]{figures/pMSSMpaper/Prior/CompareFrequentist/CompareProfileLhdWithPriorM2}
}
\hspace{2mm}
\subfloat[]{
  \includegraphics[width=65mm]{figures/pMSSMpaper/Prior/CompareFrequentist/CompareProfileLhdWithPriorM3}
}
\hspace{2mm}
\subfloat[]{
  \includegraphics[width=65mm]{figures/pMSSMpaper/Prior/CompareFrequentist/CompareProfileLhdWithPriormu}
}
\hspace{2mm}
\subfloat[]{   % ???
  \includegraphics[width=65mm]{figures/pMSSMpaper/Prior/CompareFrequentist/CompareProfileLhdWithPriormApole}
}
\hspace{2mm}
\subfloat[]{
  \includegraphics[width=65mm]{figures/pMSSMpaper/Prior/CompareFrequentist/CompareProfileLhdWithPriortanb}
}
\caption{Comparison of the frequentist profile likelihood (dashed blue line) to the non-DCS prior (solid black line) for 6 of the pMSSM parameters. }
\label{fig:PandP1}
\end{figure}


\FloatBarrier

\renewcommand*\thesubfigure{\arabic{subfigure}}
\begin{figure}[htbp]
\centering
\hspace{2mm}
\subfloat[]{
  \includegraphics[width=65mm]{figures/pMSSMpaper/Prior/CompareFrequentist/CompareProfileLhdWithPriorMq1}
}
\hspace{2mm}
\subfloat[]{
  \includegraphics[width=65mm]{figures/pMSSMpaper/Prior/CompareFrequentist/CompareProfileLhdWithPriorMq3}
}
\hspace{2mm}
\subfloat[]{
  \includegraphics[width=65mm]{figures/pMSSMpaper/Prior/CompareFrequentist/CompareProfileLhdWithPriorMu1}
}
\hspace{2mm}
\subfloat[]{
  \includegraphics[width=65mm]{figures/pMSSMpaper/Prior/CompareFrequentist/CompareProfileLhdWithPriorMu3}
}
\hspace{2mm}
\subfloat[]{
  \includegraphics[width=65mm]{figures/pMSSMpaper/Prior/CompareFrequentist/CompareProfileLhdWithPriorMd1}
}
\hspace{2mm}
\subfloat[]{
  \includegraphics[width=65mm]{figures/pMSSMpaper/Prior/CompareFrequentist/CompareProfileLhdWithPriorMd3}
}
\caption{Comparison of the frequentist profile likelihood (dashed blue line) to the non-DCS prior (solid black line) for an additional 6 of the pMSSM parameters. }
\label{fig:PandP2}
\end{figure}

\FloatBarrier

\renewcommand*\thesubfigure{\arabic{subfigure}}
\begin{figure}[htbp]
\centering
\hspace{2mm}
\subfloat[]{
  \includegraphics[width=65mm]{figures/pMSSMpaper/Prior/CompareFrequentist/CompareProfileLhdWithPriorMl1}
}
\hspace{2mm}
\subfloat[]{
  \includegraphics[width=65mm]{figures/pMSSMpaper/Prior/CompareFrequentist/CompareProfileLhdWithPriorMl3}
}
\hspace{2mm}
\subfloat[]{
  \includegraphics[width=65mm]{figures/pMSSMpaper/Prior/CompareFrequentist/CompareProfileLhdWithPriorMr1}
}
\hspace{2mm}
\subfloat[]{
  \includegraphics[width=65mm]{figures/pMSSMpaper/Prior/CompareFrequentist/CompareProfileLhdWithPriorMr3}
}
\hspace{2mm}
\subfloat[]{
  \includegraphics[width=65mm]{figures/pMSSMpaper/Prior/CompareFrequentist/CompareProfileLhdWithPriorAt}
}
\hspace{2mm}
\subfloat[]{
  \includegraphics[width=65mm]{figures/pMSSMpaper/Prior/CompareFrequentist/CompareProfileLhdWithPriorAb}
}
\caption{Comparison of the frequentist profile likelihood (dashed blue line) to the non-DCS prior (solid black line) for an additional 6 of the pMSSM parameters. }
\label{fig:PandP3}
\end{figure}

\FloatBarrier

\renewcommand*\thesubfigure{\arabic{subfigure}}
\begin{figure}[htbp]
\centering
\hspace{2mm}
\subfloat[]{
  \includegraphics[width=65mm]{figures/pMSSMpaper/Prior/CompareFrequentist/CompareProfileLhdWithPriorAl}
}
\caption{Comparison of the frequentist profile likelihood (dashed blue line) to the non-DCS prior (solid black line) for a pMSSM parameter. }
\label{fig:PandP4}
\end{figure}





